{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83fa2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:30.242715Z",
     "iopub.status.busy": "2025-01-09T16:45:30.242432Z",
     "iopub.status.idle": "2025-01-09T16:45:41.627187Z",
     "shell.execute_reply": "2025-01-09T16:45:41.626066Z"
    },
    "papermill": {
     "duration": 11.392196,
     "end_time": "2025-01-09T16:45:41.629674",
     "exception": false,
     "start_time": "2025-01-09T16:45:30.237478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models-pytorch\r\n",
      "  Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl.metadata (32 kB)\r\n",
      "Collecting efficientnet-pytorch>=0.6.1 (from segmentation-models-pytorch)\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.24.7)\r\n",
      "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (10.4.0)\r\n",
      "Collecting pretrainedmodels>=0.7.1 (from segmentation-models-pytorch)\r\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\r\n",
      "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.0.12)\r\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (2.4.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.19.1+cu121)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.5)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.16.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2024.6.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.12.2)\r\n",
      "Collecting munch (from pretrainedmodels>=0.7.1->segmentation-models-pytorch)\r\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.9->segmentation-models-pytorch) (0.4.5)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2024.8.30)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->segmentation-models-pytorch) (1.3.0)\r\n",
      "Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl (121 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16425 sha256=a148e27778d26e3d739a6f126d6ea070da94582d9288277092c90d0d2d61a855\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=0421742cc496f4dfd7cdcb5962aba8186d357aed06eec1c5315f49a67e554cb3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, efficientnet-pytorch, pretrainedmodels, segmentation-models-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.4.0\r\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\r\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\r\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.9.2)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\r\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.23.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e016484e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:41.640070Z",
     "iopub.status.busy": "2025-01-09T16:45:41.639806Z",
     "iopub.status.idle": "2025-01-09T16:45:51.586662Z",
     "shell.execute_reply": "2025-01-09T16:45:51.585899Z"
    },
    "papermill": {
     "duration": 9.953463,
     "end_time": "2025-01-09T16:45:51.588180",
     "exception": false,
     "start_time": "2025-01-09T16:45:41.634717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0222626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:51.598217Z",
     "iopub.status.busy": "2025-01-09T16:45:51.597974Z",
     "iopub.status.idle": "2025-01-09T16:45:51.756078Z",
     "shell.execute_reply": "2025-01-09T16:45:51.755209Z"
    },
    "papermill": {
     "duration": 0.164615,
     "end_time": "2025-01-09T16:45:51.757559",
     "exception": false,
     "start_time": "2025-01-09T16:45:51.592944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-4dd63193-31c8-fd85-deeb-82adc81f2930)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a9a505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:51.767811Z",
     "iopub.status.busy": "2025-01-09T16:45:51.767574Z",
     "iopub.status.idle": "2025-01-09T16:45:51.775760Z",
     "shell.execute_reply": "2025-01-09T16:45:51.775119Z"
    },
    "papermill": {
     "duration": 0.014482,
     "end_time": "2025-01-09T16:45:51.776910",
     "exception": false,
     "start_time": "2025-01-09T16:45:51.762428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 20])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160,100,20])\n",
    "        upper_red2 = np.array([179,255,255])\n",
    "        \n",
    "        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n",
    "        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n",
    "        \n",
    "        red_mask = lower_mask_red + upper_mask_red\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  # Đọc ảnh dưới dạng BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert sang RGB\n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7a6511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:51.786739Z",
     "iopub.status.busy": "2025-01-09T16:45:51.786537Z",
     "iopub.status.idle": "2025-01-09T16:45:52.858411Z",
     "shell.execute_reply": "2025-01-09T16:45:52.857471Z"
    },
    "papermill": {
     "duration": 1.078263,
     "end_time": "2025-01-09T16:45:52.859874",
     "exception": false,
     "start_time": "2025-01-09T16:45:51.781611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = []\n",
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "        \n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "342b75a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:52.870584Z",
     "iopub.status.busy": "2025-01-09T16:45:52.870286Z",
     "iopub.status.idle": "2025-01-09T16:45:53.923721Z",
     "shell.execute_reply": "2025-01-09T16:45:53.922947Z"
    },
    "papermill": {
     "duration": 1.060196,
     "end_time": "2025-01-09T16:45:53.925075",
     "exception": false,
     "start_time": "2025-01-09T16:45:52.864879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "        \n",
    "len(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e65d0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:53.935748Z",
     "iopub.status.busy": "2025-01-09T16:45:53.935440Z",
     "iopub.status.idle": "2025-01-09T16:45:53.939623Z",
     "shell.execute_reply": "2025-01-09T16:45:53.938772Z"
    },
    "papermill": {
     "duration": 0.010515,
     "end_time": "2025-01-09T16:45:53.940807",
     "exception": false,
     "start_time": "2025-01-09T16:45:53.930292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= (224,224),\n",
    "                             transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba36c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:53.951106Z",
     "iopub.status.busy": "2025-01-09T16:45:53.950903Z",
     "iopub.status.idle": "2025-01-09T16:45:54.233232Z",
     "shell.execute_reply": "2025-01-09T16:45:54.232472Z"
    },
    "papermill": {
     "duration": 0.28903,
     "end_time": "2025-01-09T16:45:54.234714",
     "exception": false,
     "start_time": "2025-01-09T16:45:53.945684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 243MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"mobilenet_v2\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5d7723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:45:54.245712Z",
     "iopub.status.busy": "2025-01-09T16:45:54.245439Z",
     "iopub.status.idle": "2025-01-09T16:46:27.214584Z",
     "shell.execute_reply": "2025-01-09T16:46:27.213814Z"
    },
    "papermill": {
     "duration": 32.976192,
     "end_time": "2025-01-09T16:46:27.216187",
     "exception": false,
     "start_time": "2025-01-09T16:45:54.239995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "images_data = []\n",
    "labels_data = []\n",
    "for x,y in dataset:\n",
    "    images_data.append(x)\n",
    "    labels_data.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b5616c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:46:27.227505Z",
     "iopub.status.busy": "2025-01-09T16:46:27.227221Z",
     "iopub.status.idle": "2025-01-09T16:46:27.232784Z",
     "shell.execute_reply": "2025-01-09T16:46:27.232124Z"
    },
    "papermill": {
     "duration": 0.012282,
     "end_time": "2025-01-09T16:46:27.233937",
     "exception": false,
     "start_time": "2025-01-09T16:46:27.221655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.targets[index]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a369d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:46:27.244231Z",
     "iopub.status.busy": "2025-01-09T16:46:27.244015Z",
     "iopub.status.idle": "2025-01-09T16:46:27.251543Z",
     "shell.execute_reply": "2025-01-09T16:46:27.250644Z"
    },
    "papermill": {
     "duration": 0.014065,
     "end_time": "2025-01-09T16:46:27.252848",
     "exception": false,
     "start_time": "2025-01-09T16:46:27.238783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-d765f530c16c>:4: UserWarning: Argument 'eps' is not valid and will be ignored.\n",
      "  A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n"
     ]
    }
   ],
   "source": [
    "train_transformation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.4),\n",
    "    A.VerticalFlip(p=0.4),\n",
    "    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transformation = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b406cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:46:27.263312Z",
     "iopub.status.busy": "2025-01-09T16:46:27.263044Z",
     "iopub.status.idle": "2025-01-09T16:46:27.267586Z",
     "shell.execute_reply": "2025-01-09T16:46:27.266782Z"
    },
    "papermill": {
     "duration": 0.011091,
     "end_time": "2025-01-09T16:46:27.268820",
     "exception": false,
     "start_time": "2025-01-09T16:46:27.257729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(images_data))\n",
    "val_size = len(images_data) - train_size\n",
    "train_dataset = CustomDataset(images_data[:train_size], labels_data[:train_size], transform=train_transformation)\n",
    "val_dataset = CustomDataset(images_data[train_size:], labels_data[train_size:], transform=val_transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b1dc38d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:46:27.279305Z",
     "iopub.status.busy": "2025-01-09T16:46:27.279065Z",
     "iopub.status.idle": "2025-01-09T16:46:27.283268Z",
     "shell.execute_reply": "2025-01-09T16:46:27.282668Z"
    },
    "papermill": {
     "duration": 0.010685,
     "end_time": "2025-01-09T16:46:27.284410",
     "exception": false,
     "start_time": "2025-01-09T16:46:27.273725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "974781cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:46:27.294777Z",
     "iopub.status.busy": "2025-01-09T16:46:27.294541Z",
     "iopub.status.idle": "2025-01-09T16:46:27.298560Z",
     "shell.execute_reply": "2025-01-09T16:46:27.297755Z"
    },
    "papermill": {
     "duration": 0.01059,
     "end_time": "2025-01-09T16:46:27.299837",
     "exception": false,
     "start_time": "2025-01-09T16:46:27.289247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2719fd3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:46:27.310189Z",
     "iopub.status.busy": "2025-01-09T16:46:27.309963Z",
     "iopub.status.idle": "2025-01-09T16:46:31.382954Z",
     "shell.execute_reply": "2025-01-09T16:46:31.381969Z"
    },
    "papermill": {
     "duration": 4.07961,
     "end_time": "2025-01-09T16:46:31.384274",
     "exception": false,
     "start_time": "2025-01-09T16:46:27.304664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrungtu041203\u001b[0m (\u001b[33mtrungtu041203-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250109_164630-06kofdv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mruby-silence-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/trungtu041203-hanoi-university-of-science-and-technology/PolypSegmentation_final\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/trungtu041203-hanoi-university-of-science-and-technology/PolypSegmentation_final/runs/06kofdv5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/trungtu041203-hanoi-university-of-science-and-technology/PolypSegmentation_final/runs/06kofdv5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x79d3f560e620>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wandb login '1d9fd10bac849cbd66c61babee442f10d87e3fc1'\n",
    "wandb.init(\n",
    "    project = 'PolypSegmentation_final'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b2e62e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:46:31.396428Z",
     "iopub.status.busy": "2025-01-09T16:46:31.396138Z",
     "iopub.status.idle": "2025-01-09T17:14:08.124555Z",
     "shell.execute_reply": "2025-01-09T17:14:08.123581Z"
    },
    "papermill": {
     "duration": 1656.749669,
     "end_time": "2025-01-09T17:14:08.139630",
     "exception": false,
     "start_time": "2025-01-09T16:46:31.389961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.3760306633\n",
      "Epoch [2/200], Loss: 0.1781529397\n",
      "Epoch [3/200], Loss: 0.1277381521\n",
      "Epoch [4/200], Loss: 0.1081953496\n",
      "Epoch [5/200], Loss: 0.0903975269\n",
      "Epoch [6/200], Loss: 0.0817114997\n",
      "Epoch [7/200], Loss: 0.0802780353\n",
      "Epoch [8/200], Loss: 0.0723422505\n",
      "Epoch [9/200], Loss: 0.0756136772\n",
      "Epoch [10/200], Loss: 0.0753202993\n",
      "Epoch [11/200], Loss: 0.0693303023\n",
      "Epoch [12/200], Loss: 0.0721743126\n",
      "Epoch [13/200], Loss: 0.0663238207\n",
      "Epoch [14/200], Loss: 0.0633092610\n",
      "Epoch [15/200], Loss: 0.0611171448\n",
      "Epoch [16/200], Loss: 0.0659630592\n",
      "Epoch [17/200], Loss: 0.0683156992\n",
      "Epoch [18/200], Loss: 0.0626505904\n",
      "Epoch [19/200], Loss: 0.0603537802\n",
      "Epoch [20/200], Loss: 0.0653587236\n",
      "Epoch [21/200], Loss: 0.0679893898\n",
      "Epoch [22/200], Loss: 0.0621481023\n",
      "Epoch [23/200], Loss: 0.0653118182\n",
      "Epoch [24/200], Loss: 0.0561254279\n",
      "Epoch [25/200], Loss: 0.0617330503\n",
      "Epoch [26/200], Loss: 0.0603325398\n",
      "Epoch [27/200], Loss: 0.0682991953\n",
      "Epoch [28/200], Loss: 0.0614489387\n",
      "Epoch [29/200], Loss: 0.0583565514\n",
      "Epoch [30/200], Loss: 0.0612340454\n",
      "Epoch [31/200], Loss: 0.0669557913\n",
      "Epoch [32/200], Loss: 0.0639050394\n",
      "Epoch [33/200], Loss: 0.0650434186\n",
      "Epoch [34/200], Loss: 0.0629107162\n",
      "Epoch [35/200], Loss: 0.0642617793\n",
      "Epoch [36/200], Loss: 0.0604772644\n",
      "Epoch [37/200], Loss: 0.0664981134\n",
      "Epoch [38/200], Loss: 0.0686756559\n",
      "Epoch [39/200], Loss: 0.0683105174\n",
      "Epoch [40/200], Loss: 0.0827011543\n",
      "Epoch [41/200], Loss: 0.0710977528\n",
      "Epoch [42/200], Loss: 0.0674462664\n",
      "Epoch [43/200], Loss: 0.0707999231\n",
      "Epoch [44/200], Loss: 0.0725018583\n",
      "Epoch [45/200], Loss: 0.0755471948\n",
      "Epoch [46/200], Loss: 0.0773246124\n",
      "Epoch [47/200], Loss: 0.0727023982\n",
      "Epoch [48/200], Loss: 0.0730973237\n",
      "Epoch [49/200], Loss: 0.0737449797\n",
      "Epoch [50/200], Loss: 0.0755467374\n",
      "Epoch [51/200], Loss: 0.0690037023\n",
      "Epoch [52/200], Loss: 0.0700726462\n",
      "Epoch [53/200], Loss: 0.0729752994\n",
      "Epoch [54/200], Loss: 0.0771469728\n",
      "Epoch [55/200], Loss: 0.0762314577\n",
      "Epoch [56/200], Loss: 0.0731670820\n",
      "Epoch [57/200], Loss: 0.0728565777\n",
      "Epoch [58/200], Loss: 0.0686941727\n",
      "Epoch [59/200], Loss: 0.0681551679\n",
      "Epoch [60/200], Loss: 0.0703071668\n",
      "Epoch [61/200], Loss: 0.0725149218\n",
      "Epoch [62/200], Loss: 0.0760277351\n",
      "Epoch [63/200], Loss: 0.0688605071\n",
      "Epoch [64/200], Loss: 0.0799796279\n",
      "Epoch [65/200], Loss: 0.0704062565\n",
      "Epoch [66/200], Loss: 0.0758714159\n",
      "Epoch [67/200], Loss: 0.0785723788\n",
      "Epoch [68/200], Loss: 0.0729876030\n",
      "Epoch [69/200], Loss: 0.0770120322\n",
      "Epoch [70/200], Loss: 0.0792525618\n",
      "Epoch [71/200], Loss: 0.0779410702\n",
      "Epoch [72/200], Loss: 0.0724462908\n",
      "Epoch [73/200], Loss: 0.0770536105\n",
      "Epoch [74/200], Loss: 0.0681844283\n",
      "Epoch [75/200], Loss: 0.0650982420\n",
      "Epoch [76/200], Loss: 0.0662294455\n",
      "Epoch [77/200], Loss: 0.0685417065\n",
      "Epoch [78/200], Loss: 0.0771106056\n",
      "Epoch [79/200], Loss: 0.0621135076\n",
      "Epoch [80/200], Loss: 0.0691078917\n",
      "Epoch [81/200], Loss: 0.0682526587\n",
      "Epoch [82/200], Loss: 0.0691485341\n",
      "Epoch [83/200], Loss: 0.0672527548\n",
      "Epoch [84/200], Loss: 0.0692596335\n",
      "Epoch [85/200], Loss: 0.0703094937\n",
      "Epoch [86/200], Loss: 0.0753438414\n",
      "Epoch [87/200], Loss: 0.0743691466\n",
      "Epoch [88/200], Loss: 0.0746187852\n",
      "Epoch [89/200], Loss: 0.0755397870\n",
      "Epoch [90/200], Loss: 0.0798252766\n",
      "Epoch [91/200], Loss: 0.0788016742\n",
      "Epoch [92/200], Loss: 0.0779260107\n",
      "Epoch [93/200], Loss: 0.0695402083\n",
      "Epoch [94/200], Loss: 0.0734397464\n",
      "Epoch [95/200], Loss: 0.0759832070\n",
      "Epoch [96/200], Loss: 0.0781968976\n",
      "Epoch [97/200], Loss: 0.0702757979\n",
      "Epoch [98/200], Loss: 0.0904507028\n",
      "Epoch [99/200], Loss: 0.0770113761\n",
      "Epoch [100/200], Loss: 0.0745502034\n",
      "Epoch [101/200], Loss: 0.0746870432\n",
      "Epoch [102/200], Loss: 0.0703594597\n",
      "Epoch [103/200], Loss: 0.0759731039\n",
      "Epoch [104/200], Loss: 0.0729943964\n",
      "Epoch [105/200], Loss: 0.0661409576\n",
      "Epoch [106/200], Loss: 0.0749127149\n",
      "Epoch [107/200], Loss: 0.0773922960\n",
      "Epoch [108/200], Loss: 0.0776782628\n",
      "Epoch [109/200], Loss: 0.0757504325\n",
      "Epoch [110/200], Loss: 0.0748704053\n",
      "Epoch [111/200], Loss: 0.0782282363\n",
      "Epoch [112/200], Loss: 0.0736716958\n",
      "Epoch [113/200], Loss: 0.0777083607\n",
      "Epoch [114/200], Loss: 0.0823801763\n",
      "Epoch [115/200], Loss: 0.0841135503\n",
      "Epoch [116/200], Loss: 0.0823850827\n",
      "Epoch [117/200], Loss: 0.0819423992\n",
      "Epoch [118/200], Loss: 0.0798038178\n",
      "Epoch [119/200], Loss: 0.0838444264\n",
      "Epoch [120/200], Loss: 0.0774417179\n",
      "Epoch [121/200], Loss: 0.0775781245\n",
      "Epoch [122/200], Loss: 0.0874114211\n",
      "Epoch [123/200], Loss: 0.0704598107\n",
      "Epoch [124/200], Loss: 0.0707132287\n",
      "Epoch [125/200], Loss: 0.0758093835\n",
      "Epoch [126/200], Loss: 0.0753436223\n",
      "Epoch [127/200], Loss: 0.0804084120\n",
      "Epoch [128/200], Loss: 0.0814331162\n",
      "Epoch [129/200], Loss: 0.0808137067\n",
      "Epoch [130/200], Loss: 0.0836388095\n",
      "Epoch [131/200], Loss: 0.0793874715\n",
      "Epoch [132/200], Loss: 0.0790745790\n",
      "Epoch [133/200], Loss: 0.0786772649\n",
      "Epoch [134/200], Loss: 0.0762575882\n",
      "Epoch [135/200], Loss: 0.0820867310\n",
      "Epoch [136/200], Loss: 0.0877130749\n",
      "Epoch [137/200], Loss: 0.0862054187\n",
      "Epoch [138/200], Loss: 0.0914041079\n",
      "Epoch [139/200], Loss: 0.0868834879\n",
      "Epoch [140/200], Loss: 0.0891828226\n",
      "Epoch [141/200], Loss: 0.0895570651\n",
      "Epoch [142/200], Loss: 0.0897898454\n",
      "Epoch [143/200], Loss: 0.0909781966\n",
      "Epoch [144/200], Loss: 0.0850268845\n",
      "Epoch [145/200], Loss: 0.0881595959\n",
      "Epoch [146/200], Loss: 0.0792351889\n",
      "Epoch [147/200], Loss: 0.0863642798\n",
      "Epoch [148/200], Loss: 0.1035095857\n",
      "Epoch [149/200], Loss: 0.0876515046\n",
      "Epoch [150/200], Loss: 0.0869979693\n",
      "Epoch [151/200], Loss: 0.0887833727\n",
      "Epoch [152/200], Loss: 0.0919464393\n",
      "Epoch [153/200], Loss: 0.0881520011\n",
      "Epoch [154/200], Loss: 0.0958221327\n",
      "Epoch [155/200], Loss: 0.0942320399\n",
      "Epoch [156/200], Loss: 0.0963888016\n",
      "Epoch [157/200], Loss: 0.0963872430\n",
      "Epoch [158/200], Loss: 0.0949067782\n",
      "Epoch [159/200], Loss: 0.0970558042\n",
      "Epoch [160/200], Loss: 0.0964561565\n",
      "Epoch [161/200], Loss: 0.0960379979\n",
      "Epoch [162/200], Loss: 0.0967374707\n",
      "Epoch [163/200], Loss: 0.1001335854\n",
      "Epoch [164/200], Loss: 0.0948933877\n",
      "Epoch [165/200], Loss: 0.1023716488\n",
      "Epoch [166/200], Loss: 0.1037884916\n",
      "Epoch [167/200], Loss: 0.0972035650\n",
      "Epoch [168/200], Loss: 0.0931604592\n",
      "Epoch [169/200], Loss: 0.0972846329\n",
      "Epoch [170/200], Loss: 0.0941094748\n",
      "Epoch [171/200], Loss: 0.0957686134\n",
      "Epoch [172/200], Loss: 0.0997530118\n",
      "Epoch [173/200], Loss: 0.0938644884\n",
      "Epoch [174/200], Loss: 0.0912180792\n",
      "Epoch [175/200], Loss: 0.0863585400\n",
      "Epoch [176/200], Loss: 0.0778497943\n",
      "Epoch [177/200], Loss: 0.0913242500\n",
      "Epoch [178/200], Loss: 0.0901660323\n",
      "Epoch [179/200], Loss: 0.0931648758\n",
      "Epoch [180/200], Loss: 0.0925110939\n",
      "Epoch [181/200], Loss: 0.0937821503\n",
      "Epoch [182/200], Loss: 0.0931020125\n",
      "Epoch [183/200], Loss: 0.0938513176\n",
      "Epoch [184/200], Loss: 0.0962678177\n",
      "Epoch [185/200], Loss: 0.0915364426\n",
      "Epoch [186/200], Loss: 0.0888611374\n",
      "Epoch [187/200], Loss: 0.0945564297\n",
      "Epoch [188/200], Loss: 0.0999424481\n",
      "Epoch [189/200], Loss: 0.0986015572\n",
      "Epoch [190/200], Loss: 0.0932038684\n",
      "Epoch [191/200], Loss: 0.0977893253\n",
      "Epoch [192/200], Loss: 0.1026596434\n",
      "Epoch [193/200], Loss: 0.1054655420\n",
      "Epoch [194/200], Loss: 0.1022065346\n",
      "Epoch [195/200], Loss: 0.1036864683\n",
      "Epoch [196/200], Loss: 0.1005601421\n",
      "Epoch [197/200], Loss: 0.1013151670\n",
      "Epoch [198/200], Loss: 0.0937008149\n",
      "Epoch [199/200], Loss: 0.0903648616\n",
      "Epoch [200/200], Loss: 0.1006609919\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_val_loss = 999\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        outputs = model(images)\n",
    "    \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            val_loss += criterion(outputs.float(),labels.long()).item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = f'unet++_mobilenet_checkpoint.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "    wandb.log({'Val_loss': val_loss/len(val_loader),'Train_loss': train_loss/len(train_loader)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "822e8501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:14:08.167869Z",
     "iopub.status.busy": "2025-01-09T17:14:08.167577Z",
     "iopub.status.idle": "2025-01-09T17:14:08.351771Z",
     "shell.execute_reply": "2025-01-09T17:14:08.350818Z"
    },
    "papermill": {
     "duration": 0.199885,
     "end_time": "2025-01-09T17:14:08.353125",
     "exception": false,
     "start_time": "2025-01-09T17:14:08.153240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-619af636f292>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/kaggle/working/unet++_mobilenet_checkpoint.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UnetPlusPlus(\n",
       "  (encoder): MobileNetV2Encoder(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetPlusPlusDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleDict(\n",
       "      (x_0_0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1376, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(200, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(80, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(56, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(72, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(56, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_3_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(40, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('/kaggle/working/unet++_mobilenet_checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e7aa2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:14:08.382868Z",
     "iopub.status.busy": "2025-01-09T17:14:08.382608Z",
     "iopub.status.idle": "2025-01-09T17:14:08.541137Z",
     "shell.execute_reply": "2025-01-09T17:14:08.539892Z"
    },
    "papermill": {
     "duration": 0.174841,
     "end_time": "2025-01-09T17:14:08.542726",
     "exception": false,
     "start_time": "2025-01-09T17:14:08.367885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "659a7da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:14:08.574660Z",
     "iopub.status.busy": "2025-01-09T17:14:08.574383Z",
     "iopub.status.idle": "2025-01-09T17:14:26.603049Z",
     "shell.execute_reply": "2025-01-09T17:14:26.602340Z"
    },
    "papermill": {
     "duration": 18.044988,
     "end_time": "2025-01-09T17:14:26.604595",
     "exception": false,
     "start_time": "2025-01-09T17:14:08.559607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n",
    "    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n",
    "    ori_img = cv2.imread(img_path)\n",
    "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    ori_w = ori_img.shape[0]\n",
    "    ori_h = ori_img.shape[1]\n",
    "    img = cv2.resize(ori_img, (224, 224))\n",
    "    transformed = val_transformation(image=img)\n",
    "    input_img = transformed[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n",
    "    mask = cv2.resize(output_mask, (ori_h, ori_w))\n",
    "    mask = np.argmax(mask, axis=2)\n",
    "    mask_rgb = mask_to_rgb(mask, color_dict)\n",
    "    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5110960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:14:26.634814Z",
     "iopub.status.busy": "2025-01-09T17:14:26.634544Z",
     "iopub.status.idle": "2025-01-09T17:14:28.209776Z",
     "shell.execute_reply": "2025-01-09T17:14:28.208856Z"
    },
    "papermill": {
     "duration": 1.591476,
     "end_time": "2025-01-09T17:14:28.211166",
     "exception": false,
     "start_time": "2025-01-09T17:14:26.619690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/prediction/be86f03d900fd197cd955fa095f97845.jpeg\n",
      "/kaggle/working/prediction/eb1ef57af2ed9fbb63b28163a745959c.jpeg\n",
      "/kaggle/working/prediction/39dda50f954ba59c7de13a35276a4764.jpeg\n",
      "/kaggle/working/prediction/7f0019f7e6af7d7147763bdfb928d788.jpeg\n",
      "/kaggle/working/prediction/6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n",
      "/kaggle/working/prediction/afe1f119f21b248d152b672ab3492fc6.jpeg\n",
      "/kaggle/working/prediction/782707d7c359e27888daefee82519763.jpeg\n",
      "/kaggle/working/prediction/3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n",
      "/kaggle/working/prediction/bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n",
      "/kaggle/working/prediction/6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n",
      "/kaggle/working/prediction/a9d45c3dbc695325ded465efde988dfb.jpeg\n",
      "/kaggle/working/prediction/314fe384eb2ba3adfda6c1899fdc9837.jpeg\n",
      "/kaggle/working/prediction/c41545ba55aadaa77712a48e11d579d9.jpeg\n",
      "/kaggle/working/prediction/cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n",
      "/kaggle/working/prediction/285e26c90e1797c77826f9a7021bab9f.jpeg\n",
      "/kaggle/working/prediction/e1e0ae936de314f2d95e6c487ffa651b.jpeg\n",
      "/kaggle/working/prediction/dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n",
      "/kaggle/working/prediction/6f4d4987ea3b4bae5672a230194c5a08.jpeg\n",
      "/kaggle/working/prediction/692195f853af7f8a4df1ec859759b7c8.jpeg\n",
      "/kaggle/working/prediction/6679bff55177a34fc01019eec999fd84.jpeg\n",
      "/kaggle/working/prediction/5a51625559c7e610b1531871f2fd85a0.jpeg\n",
      "/kaggle/working/prediction/cf6644589e532a9ee954f81faedbce39.jpeg\n",
      "/kaggle/working/prediction/8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n",
      "/kaggle/working/prediction/1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n",
      "/kaggle/working/prediction/27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n",
      "/kaggle/working/prediction/c4be73749a0d21db70dd094a7f32574d.jpeg\n",
      "/kaggle/working/prediction/e4a17af18f72c8e6166a915669c99390.jpeg\n",
      "/kaggle/working/prediction/7af2ed9fbb63b28163a745959c039830.jpeg\n",
      "/kaggle/working/prediction/7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n",
      "/kaggle/working/prediction/cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n",
      "/kaggle/working/prediction/b21960c94b0aab4c024a573c692195f8.jpeg\n",
      "/kaggle/working/prediction/be4d18d5401f659532897255ce2dd4ae.jpeg\n",
      "/kaggle/working/prediction/66e057db382b8564872a27301a654864.jpeg\n",
      "/kaggle/working/prediction/936de314f2d95e6c487ffa651b477422.jpeg\n",
      "/kaggle/working/prediction/77e004e8bfb905b78a91391adc0bb223.jpeg\n",
      "/kaggle/working/prediction/fe1f119f21b248d152b672ab3492fc62.jpeg\n",
      "/kaggle/working/prediction/d694539ef2424a9218697283baa3657e.jpeg\n",
      "/kaggle/working/prediction/559c7e610b1531871f2fd85a04faeeb2.jpeg\n",
      "/kaggle/working/prediction/c695325ded465efde988dfb96d081533.jpeg\n",
      "/kaggle/working/prediction/e1797c77826f9a7021bab9fc73303988.jpeg\n",
      "/kaggle/working/prediction/b70dd094a7f32574d6c748c41743c6c0.jpeg\n",
      "/kaggle/working/prediction/e73749a0d21db70dd094a7f32574d6c7.jpeg\n",
      "/kaggle/working/prediction/cb1b387133b51209db6dcdda5cc8a788.jpeg\n",
      "/kaggle/working/prediction/72d9e593b6be1ac29adbe86f03d900fd.jpeg\n",
      "/kaggle/working/prediction/dd78294679c9cbb2a365b5574868eb60.jpeg\n",
      "/kaggle/working/prediction/633a8d5b2b2b55157b7781e2c706c75c.jpeg\n",
      "/kaggle/working/prediction/26679bff55177a34fc01019eec999fd8.jpeg\n",
      "/kaggle/working/prediction/1531871f2fd85a04faeeb2b535797395.jpeg\n",
      "/kaggle/working/prediction/cc5cfd263f1f90be28799235026b3550.jpeg\n",
      "/kaggle/working/prediction/97e1c0e9082ea2c193ac8d551c149b60.jpeg\n",
      "/kaggle/working/prediction/41ed86e58224cb76a67d4dcf9596154e.jpeg\n",
      "/kaggle/working/prediction/4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n",
      "/kaggle/working/prediction/4baddc22268d4b4ef4d95ceea1195799.jpeg\n",
      "/kaggle/working/prediction/395e56a6d9ba9d45c3dbc695325ded46.jpeg\n",
      "/kaggle/working/prediction/6b83ef461c2a337948a41964c1d4f50a.jpeg\n",
      "/kaggle/working/prediction/7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n",
      "/kaggle/working/prediction/6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n",
      "/kaggle/working/prediction/e3c84417fda8019410b1fcf0625f608b.jpeg\n",
      "/kaggle/working/prediction/e9082ea2c193ac8d551c149b60f29653.jpeg\n",
      "/kaggle/working/prediction/e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n",
      "/kaggle/working/prediction/f13dd311a65d2b46d0a6085835c525af.jpeg\n",
      "/kaggle/working/prediction/5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n",
      "/kaggle/working/prediction/aeeb2b535797395305af926a6f23c5d6.jpeg\n",
      "/kaggle/working/prediction/df8e26031fbb5e52c41545ba55aadaa7.jpeg\n",
      "/kaggle/working/prediction/677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n",
      "/kaggle/working/prediction/54ba59c7de13a35276a476420655433a.jpeg\n",
      "/kaggle/working/prediction/d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n",
      "/kaggle/working/prediction/6ad1468996b4a9ce6d840b53a6558038.jpeg\n",
      "/kaggle/working/prediction/5b21960c94b0aab4c024a573c692195f.jpeg\n",
      "/kaggle/working/prediction/a51625559c7e610b1531871f2fd85a04.jpeg\n",
      "/kaggle/working/prediction/8cbdf366e057db382b8564872a27301a.jpeg\n",
      "/kaggle/working/prediction/13dd311a65d2b46d0a6085835c525af6.jpeg\n",
      "/kaggle/working/prediction/4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n",
      "/kaggle/working/prediction/e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n",
      "/kaggle/working/prediction/998906d3694abb47953b0e4909384b57.jpeg\n",
      "/kaggle/working/prediction/af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n",
      "/kaggle/working/prediction/ff55177a34fc01019eec999fd84e679b.jpeg\n",
      "/kaggle/working/prediction/82ea2c193ac8d551c149b60f2965341c.jpeg\n",
      "/kaggle/working/prediction/4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n",
      "/kaggle/working/prediction/4f437f0019f7e6af7d7147763bdfb928.jpeg\n",
      "/kaggle/working/prediction/c656702fa602bb3c7abacdbd7e6afd56.jpeg\n",
      "/kaggle/working/prediction/ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n",
      "/kaggle/working/prediction/60b246359c68c836f843dcf41f4dce3c.jpeg\n",
      "/kaggle/working/prediction/3b8318ecf467d7ad048df39beb176363.jpeg\n",
      "/kaggle/working/prediction/c22268d4b4ef4d95ceea11957998906d.jpeg\n",
      "/kaggle/working/prediction/5beb48f0be11d0309d1dff09b8405734.jpeg\n",
      "/kaggle/working/prediction/02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n",
      "/kaggle/working/prediction/3dd311a65d2b46d0a6085835c525af63.jpeg\n",
      "/kaggle/working/prediction/6d3694abb47953b0e4909384b57bb6a0.jpeg\n",
      "/kaggle/working/prediction/4ef4d95ceea11957998906d3694abb47.jpeg\n",
      "/kaggle/working/prediction/67d4dcf9596154efb7cef748d9cbd617.jpeg\n",
      "/kaggle/working/prediction/cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n",
      "/kaggle/working/prediction/4417fda8019410b1fcf0625f608b4ce9.jpeg\n",
      "/kaggle/working/prediction/87133b51209db6dcdda5cc8a788edaeb.jpeg\n",
      "/kaggle/working/prediction/3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n",
      "/kaggle/working/prediction/626650908b1cb932a767bf5487ced51b.jpeg\n",
      "/kaggle/working/prediction/f8e26031fbb5e52c41545ba55aadaa77.jpeg\n",
      "/kaggle/working/prediction/eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n",
      "/kaggle/working/prediction/a6d9ba9d45c3dbc695325ded465efde9.jpeg\n",
      "/kaggle/working/prediction/ea42b4eebc9e5a87e443434ac60af150.jpeg\n",
      "/kaggle/working/prediction/d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n",
      "/kaggle/working/prediction/625559c7e610b1531871f2fd85a04fae.jpeg\n",
      "/kaggle/working/prediction/425b976973f13dd311a65d2b46d0a608.jpeg\n",
      "/kaggle/working/prediction/461c2a337948a41964c1d4f50a5f3601.jpeg\n",
      "/kaggle/working/prediction/0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n",
      "/kaggle/working/prediction/f62f215f0da4ad3a7ab8df9da7386835.jpeg\n",
      "/kaggle/working/prediction/eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n",
      "/kaggle/working/prediction/aafac813fe3ccba3e032dd2948a80c64.jpeg\n",
      "/kaggle/working/prediction/db5eb2a0e4b50889d874c68c030b9afe.jpeg\n",
      "/kaggle/working/prediction/e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n",
      "/kaggle/working/prediction/5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n",
      "/kaggle/working/prediction/0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n",
      "/kaggle/working/prediction/63b8318ecf467d7ad048df39beb17636.jpeg\n",
      "/kaggle/working/prediction/9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n",
      "/kaggle/working/prediction/f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n",
      "/kaggle/working/prediction/3c84417fda8019410b1fcf0625f608b4.jpeg\n",
      "/kaggle/working/prediction/dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n",
      "/kaggle/working/prediction/c193ac8d551c149b60f2965341caf528.jpeg\n",
      "/kaggle/working/prediction/c5a0808bee60b246359c68c836f843dc.jpeg\n",
      "/kaggle/working/prediction/8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n",
      "/kaggle/working/prediction/1c0e9082ea2c193ac8d551c149b60f29.jpeg\n",
      "/kaggle/working/prediction/e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n",
      "/kaggle/working/prediction/ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n",
      "/kaggle/working/prediction/3c692195f853af7f8a4df1ec859759b7.jpeg\n",
      "/kaggle/working/prediction/e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n",
      "/kaggle/working/prediction/e19769fa2d37d32780fd497e1c0e9082.jpeg\n",
      "/kaggle/working/prediction/d077bad31c8c5f54ffaa27a623511c38.jpeg\n",
      "/kaggle/working/prediction/15fc656702fa602bb3c7abacdbd7e6af.jpeg\n",
      "/kaggle/working/prediction/50534bca540e24f489284b8e6953ad88.jpeg\n",
      "/kaggle/working/prediction/df366e057db382b8564872a27301a654.jpeg\n",
      "/kaggle/working/prediction/7fda8019410b1fcf0625f608b4ce9762.jpeg\n",
      "/kaggle/working/prediction/a6a4248a41e8db8b4ed633b456aaafac.jpeg\n",
      "/kaggle/working/prediction/6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n",
      "/kaggle/working/prediction/a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n",
      "/kaggle/working/prediction/7936140a2d5fc1443c4e445927738677.jpeg\n",
      "/kaggle/working/prediction/5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n",
      "/kaggle/working/prediction/c7e610b1531871f2fd85a04faeeb2b53.jpeg\n",
      "/kaggle/working/prediction/710d568df17586ad8f3297c819c90895.jpeg\n",
      "/kaggle/working/prediction/4ca6160127cd1d5ff99c267599fc487b.jpeg\n",
      "/kaggle/working/prediction/5026b3550534bca540e24f489284b8e6.jpeg\n",
      "/kaggle/working/prediction/2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n",
      "/kaggle/working/prediction/1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n",
      "/kaggle/working/prediction/1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n",
      "/kaggle/working/prediction/dd094a7f32574d6c748c41743c6c08a1.jpeg\n",
      "/kaggle/working/prediction/019410b1fcf0625f608b4ce97629ab55.jpeg\n",
      "/kaggle/working/prediction/3425b976973f13dd311a65d2b46d0a60.jpeg\n",
      "/kaggle/working/prediction/a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n",
      "/kaggle/working/prediction/7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n",
      "/kaggle/working/prediction/cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n",
      "/kaggle/working/prediction/05734fbeedd0f9da760db74a29abdb04.jpeg\n",
      "/kaggle/working/prediction/f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n",
      "/kaggle/working/prediction/f7fdb2d45b21960c94b0aab4c024a573.jpeg\n",
      "/kaggle/working/prediction/9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n",
      "/kaggle/working/prediction/1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n",
      "/kaggle/working/prediction/2ed9fbb63b28163a745959c03983064a.jpeg\n",
      "/kaggle/working/prediction/7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n",
      "/kaggle/working/prediction/fb905b78a91391adc0bb223c4eaf3372.jpeg\n",
      "/kaggle/working/prediction/60a633a8d5b2b2b55157b7781e2c706c.jpeg\n",
      "/kaggle/working/prediction/fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n",
      "/kaggle/working/prediction/9c7976c1182df0de51d32128c358d1fd.jpeg\n",
      "/kaggle/working/prediction/68d4b4ef4d95ceea11957998906d3694.jpeg\n",
      "/kaggle/working/prediction/98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n",
      "/kaggle/working/prediction/4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n",
      "/kaggle/working/prediction/0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n",
      "/kaggle/working/prediction/45b21960c94b0aab4c024a573c692195.jpeg\n",
      "/kaggle/working/prediction/8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n",
      "/kaggle/working/prediction/30c2f4fc276ed9f178dc2f4af6266509.jpeg\n",
      "/kaggle/working/prediction/3bbc04a3afe1f119f21b248d152b672a.jpeg\n",
      "/kaggle/working/prediction/780fd497e1c0e9082ea2c193ac8d551c.jpeg\n",
      "/kaggle/working/prediction/268d4b4ef4d95ceea11957998906d369.jpeg\n",
      "/kaggle/working/prediction/0a0317371a966bf4b3466463a3c64db1.jpeg\n",
      "/kaggle/working/prediction/ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n",
      "/kaggle/working/prediction/318ecf467d7ad048df39beb176363408.jpeg\n",
      "/kaggle/working/prediction/2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n",
      "/kaggle/working/prediction/1db239dda50f954ba59c7de13a35276a.jpeg\n",
      "/kaggle/working/prediction/faef7fdb2d45b21960c94b0aab4c024a.jpeg\n",
      "/kaggle/working/prediction/94a7f32574d6c748c41743c6c08a1d1a.jpeg\n",
      "/kaggle/working/prediction/0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n",
      "/kaggle/working/prediction/7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n",
      "/kaggle/working/prediction/80c643782707d7c359e27888daefee82.jpeg\n",
      "/kaggle/working/prediction/a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n",
      "/kaggle/working/prediction/8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n",
      "/kaggle/working/prediction/d3694abb47953b0e4909384b57bb6a05.jpeg\n",
      "/kaggle/working/prediction/39d6aad6bb0170a40ed32deef71fbe08.jpeg\n",
      "/kaggle/working/prediction/d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n",
      "/kaggle/working/prediction/85a04faeeb2b535797395305af926a6f.jpeg\n",
      "/kaggle/working/prediction/7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n",
      "/kaggle/working/prediction/3657e4314fe384eb2ba3adfda6c1899f.jpeg\n",
      "/kaggle/working/prediction/80cae6daedd989517cb8041ed86e5822.jpeg\n",
      "/kaggle/working/prediction/71f2fd85a04faeeb2b535797395305af.jpeg\n",
      "/kaggle/working/prediction/343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n",
      "/kaggle/working/prediction/391adc0bb223c4eaf3372eae567c94ea.jpeg\n",
      "/kaggle/working/prediction/a3657e4314fe384eb2ba3adfda6c1899.jpeg\n",
      "/kaggle/working/prediction/05b78a91391adc0bb223c4eaf3372eae.jpeg\n",
      "/kaggle/working/prediction/2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n",
      "/kaggle/working/prediction/fcd6da15fc656702fa602bb3c7abacdb.jpeg\n",
      "/kaggle/working/prediction/88e16d4ca6160127cd1d5ff99c267599.jpeg\n",
      "/kaggle/working/prediction/8fa8625605da2023387fd56c04414eaa.jpeg\n",
      "/kaggle/working/prediction/0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n",
      "/kaggle/working/prediction/0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n"
     ]
    }
   ],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'unet++_mobilenet_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0316e",
   "metadata": {
    "papermill": {
     "duration": 0.014341,
     "end_time": "2025-01-09T17:14:28.241016",
     "exception": false,
     "start_time": "2025-01-09T17:14:28.226675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1742.873612,
   "end_time": "2025-01-09T17:14:30.974688",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-09T16:45:28.101076",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
